% !Mode:: "TeX:UTF-8"
\chapter{人脸多属性属性识别的架构}
在具体介绍人脸属性的任务过程中，首先对于对于人脸属性的一些常见问题做简单的介绍：
人脸属性识别的输入一般为具体的RGB图片，同时至少带有人脸检测输出的人脸框以及用于人脸矫正的landmark，实际实验证明，经过矫正的人脸对于和人脸姿势无关的属性具有很好的提升。简单介绍一下人脸矫正的过程：
人脸矫正顾名思义：就是将不够“端正”人脸调整到标准的大小，位置和姿态，这样可以让人脸都在同样的环境下进行比较，人的面部姿态一般会从roll(平面旋转), pitch(左右侧脸)和yaw(抬头低头)三个维度来描述。平面旋转很容易处理，只需将图片旋转一个角度调整至水平即可。而侧脸和低头处理起来比较有挑战，但通过放射变化也可以较好的解决。
经过人脸矫正之后，不同的算法和模型其实是对人脸矫正之后的图片或者说一定3*H*W维数值分布在(0-255)的向量空间进行各种线性和非线性计算，最后输出图片对应的属性分类标签的过程。

（加一个简单的流程图）

下面分别从人脸数据库，人脸属性的单模型预测、人脸属性的多任务预测几个角度对个人研究相关的人脸属性识别领域进行一下介绍，并且对于自身的创新工作和相关任务进行说明。
\section{人脸属性数据库的分析与简介}
人脸属性的数据库是根据人脸的标签进行标注和构建的的，其中标签往往具有很多种表示和性质，具体包括：
有序性与无序性：
无序性：无序性的属性有两个或两个以上的类别（值），但在类别之间没有内在的顺序。 例如，种族是具有多个类别的名义属性，例如黑色，白色，亚洲等，并且这些值（类别）没有内在排序。
有序性：有序性的属性具有明确的变量排序。 例如，一个人的年龄，通常从0到100，是不平均的。（实际上，年龄不仅是相互独立的存在，在不同的年龄标签中，具有一定钟形的分布）
整体性与局部性。 
整体性：整体性标签描述了整个人脸的特征，诸如年龄，性别，种族等
局部性：和整体性标签相反，局部性描述了部分人脸的特征，例如：尖鼻子，大嘴唇等。
类似的对于人脸属性的分析还有很多，比如限制性场景和非限制性场景（如固定摄像头拍摄和日常采集的场景），相对的性标注和绝对属性标注（如颜值数据标注之间只有相互的高低，但没有绝对的属性标签）本文中也主要根据上面的人脸属性的性质来设计网络和分析问题。
在早期，数据集通常只有一种属性的标注，比如之前提到的FG-NET，它包含82个目标的1002张图像，只有年龄属性。近来，很多人脸数据集都有多属性标注。比如，MORPH、celeA等。下面对相关的数据集进行详细的介绍
\textbf{MOROH II：}MORPH是一个大型的mugshot图像数据库，每个数据库都有相关的元数据，包含三个标注属性：年龄（有序），性别（无序）和种族（无序）。通过调查MORPH Album II（MORPH II）上的所有三个属性估计任务，其中包含大约78K的超过20K个主题的图像。在MORPH II上的结果五等分数据进行交叉验证。
{todo MOrph加入示例图片}
\textbf{CelebA：}CelebA是一个大型的人脸属性数据库拥有超过10万个身份的200K个名人图像，每个人拥有40个属性注释。该数据集中的图像在姿态，表情，种族，背景等方面存在较大的变化，使得面部属性估计具有挑战性。此外，由于有40个属性标注，CelebA数据库在特征学习效率方面对联合属性估计算法提出了挑战。 CelebA的结果按照[23]中提供的协议报告。 

（加入celeA属性表 todo）

\textbf{LFWA：}LFWA是另一个无约束的人脸属性数据库[23]，其中包含来自LFW数据库的脸部图像（5,749个主题的13,233张图像）[52]，以及与CelebA数据库中相同的40个属性注释。按照[23]中提供的方案报告LFWA的结果。

\textbf{Chalearn LAP and FotW：}ChaLearn挑战系列从2011年开始，在促进人们视觉或多模式分析方面取得了非常成功的成果[53]。 
LAPAge2015是一个无约束的脸部数据库，用于在ICCV 2015.5上发布的视在年龄估计。该数据库包含4,699张脸部图像，每个平均年龄至少由10个不同的用户估算。数据库被分割为2,476张图像进行训练，1,136张图像进行验证，1,087张图像进行测试[51]。由于年龄信息的测试不可用，我们遵循[17]的协议，主要使用validation集进行测试。 FotW数据库是通过收集来自互联网的公开可用图像创建的，其中包含两个数据集，一个用于辅助分类，另一个用于性别和微笑分类。 FotW数据集分别包含5,651,2,826和4,086幅用于训练，验证和测试的面部图像; 每个都用七个二进制附件属性注释（见表5（a））。 FotW性别和笑容数据集分别由6171个，3086个和8505个面部图像组成，用于训练，验证和测试; 每个都注明三元性别（男性，女性，不确定）和二元微笑的属性。 我们遵循相同的测试协议在FotW上报告结果。

\textbf{LFW+：}LFW+是扩展了LFW数据库[52]，从无约束的人脸图像研究联合属性估计（年龄，性别和种族）。由于LFW数据库中的年轻受试者（例如0-20岁年龄段）的数量非常少（根据MTurk工作者提供的标签，在5,749名受试者中仅有209该年龄段的受试者），LFW数据库通过收集2,466使用Google图片搜索服务，在0-20岁年龄范围内的受试者的脸部图像不受约束。具体而言，我们首先使用“baby”，“小孩”和“青少年”等关键词从Google图片中找到约5000幅感兴趣的图片。然后将Viola-Jones [54]人脸检测器应用于生成一组候选人脸。最后，我们手动删除了错误的脸部检测以及大多数似乎超过20个的主题。扩展的LFW数据库（LFW +）包含约8,699个受试者的约15,699个无限制面部图像。对于每个脸部图像，要求三个MTurk工作者提供他们的估计年龄，性别和种族。表观年龄被定义为三次估计的平均值，性别和种族由多数票决定。在LFW +上的结果用五折，主题独特的交叉验证方案报道。

\textbf{}

这些数据库可以根据所使用的注释方法分为三类：（i）具有名义和有序属性的数据库（MORPH II和LFW +），（ii）具有二进制属性的数据库（CelebA，LFWA和FWW）和（iii） 具有单个属性的数据库（LAPAge2015）。 我们可以看到，除了MORPH II数据库，其他五个数据库主要包含无约束的人脸图像。 对这些数据库的属性估计评估可以提供真实应用场景下系统性能的见解。 


\section{人脸属性识别的单任务模型}
基于人脸属性的单任务模型STL（下称单任务模型），顾名思义就是给定一个图像，建立一个模型去对一个属性进行学习。这不仅是人脸属性识别任务中的常见做法，也是整个模式识别领域基础的框架模式，。
作为一个分类问题，一些常见的模式识别方法也被应用其中，例如主动外观模型AAM（Active  Appearance  Model），局部二值模式LBP（Local binary patterns），加窗傅立叶变换（Gabor）等，这些常规的做法，总体来讲还是遵循特征提取工程再加上分类器模型的流程，包括特征相关性的筛选，不同模型的融合等等。但是很多时候根据固定模式提取的特征往往不够具有代表性，与识别任务的关联性不够高。于是大家开始着力想寻找一些相关性更高的方法包括，Fu等将流形学习方法引入年龄估计；另外，Guo等提出了生物启发的特征方法，Hu提出了统计信息特征（Dif，Demographic informative feature）的概念；但是时至今日，CNN特征在图像领域的出色表现，让人们对于单任务模型的使用和理解有了非常大的提高，我们根据日常的使用的经验和学术界普遍的做法总结了一套非常简练有效的的框架：
在介绍这套框架之前，首先对于hu的DIF方法做一下简单的介绍，让大家对于常规的单属性任务模型有所了解，并且作为对比：
hu的基本框架概述如下：前端为特征提取阶段，旨在提取对属性有判别力的特征，而不是完全无监督的。后端连接一个层级式的分类器，用于属性学习。
（Todo hu算法的框架，截图）

其中有几个主要部分：DIF（Demographic informative features）特征提取，层级式分类器，人机对于单属性预测任务的对比
1）DIF特征
DIF（Demographic informative features）是基于BIF（生物启发式特征）的。比如，输入一个人脸部件，先用Gabor滤波器提特征（12个尺度，8个方向），再做一些池化操作，以减小特征图的数目和维度（6个尺度，8个方向），将得到的特征串成一个4280维的长向量，用来做之后的分类等任务。总体上还是一个无监督的特征处理方法。所以之后，又对此工作做了改进，旨在不仅能够抓住图像细节，还能减小冗余性，提高特征与最终识别任务的相关性。
这一部分主要引入一些特征学习工作，从之前的特征集中不断特征子集，挑选出最相关的特征，比如：学习一个新的特征子空间（如LDA），基于Boosting的特征选择。
2）层级分类器的建设
层级分类器主要针对年龄。比如，首先进行年龄组分类（针对数据集设定阈值），在此按是否超过18岁分为两类；低于18岁的一类再判断是否低于7岁，再分为两类，然后低于7岁再进行回归得到具体的年龄数值，以此类推，先一层一层地通过多个分类器树形展开得到具体的人脸年龄段，然后在具体的人连年龄分段中及进行回归。hu的实验证明，这种层级式的分类方式要优于直接分类方法。
3）人机性能对比
在人和机器的性能对比，hu当时规模最大的数据集来衡量并对比人和机器的性能。数据集包含以下几个方面：FG-NET，年龄估计；MORPH（2000张图片），年龄、性别、种族估计；PCSO（2000）张图片，年龄、性别、种族估计
实验显示这种dif的方法取得了当时最好的结果，具有最小误差，且具有非常好的演示和出色的数学模型和理论推导。
在人和机器的性能对比，可以看出机器识别能力的绝对误差要小于人类。当在做年龄估计时，算法估计偏差比较平衡。而人类往往会将年龄估计偏高。这里是误差分析，我们发现，虽然总体上机器性能高于人，但是机器会犯一些偏离实际较大的低级错误，这也是很多学习算法的共同问题。年龄估计，实验表明，算法对真实年龄和人类标注的表观年龄的估计偏差并不大。总体来讲机器的表现可圈可点。

但是需要注意的是在这个过程中，这个工作得益于作者的精心调试和改进，技术细节较为复杂很可能一个步骤做不好就整个系统崩溃，同时因为图片数据库和过多人工干预导致了一定程度上的局部最优解，在真实场景中，难以取得良好的效果，

下面介绍神经网络中的单模型预测框架，得益于现代神经网络的出色表现，单属性预测模型的pipeline得到了极大的简化，同时结合端到端的设计思路和数据量的增加可以很好的提升单属性模型的预测效果。
CNN算法下的单模型输出预测：
首先经过图像预测处模块，将图像通过一些基础的图形变换转到统一的形变空间中，常见的操作包括图像识别任务中的空间颜色变换，尺度统一化，多尺度变换，多位置截取等。在人脸属性的人物之中，我们经常采用的方式是人脸alignment，也就是根据人脸检测输出的人脸边框位置和landmark，通过仿射变换，将人脸图像中的关键点映射到图像中的标准位置。

然后设计网络结构作为图像特征网络提取模块，这一部分往往有两条规则可以遵循从而有效的搭建神经网络结构，第一规则是根据现有的经典神经网络结构进行改进，比如alexnet，googlnet，resnet等，这样做有两方面考虑，一部分是因为这些网络在实际使用中“久经考验”，体现出了良好的收敛性能，另一方面由于类似的神经网络在科研的过程中使用的人数和场景比较多，在搭建和调参上会有很多共同的地方可以互相交流，也方便不同方法的比较。
所以总结来讲，其实如果主要的研究问题不在网络结构后对于识别任务的影响上，一般还是会使用业界通用的网络结构。
第二条规则就是在自己设计附加的网络结构过程中，也要符合一定的网络特性，包括结构上的自洽，设计之中不能产生模块之间不匹配的情况，比如同一层网络输入大小相互有差别，网络操作参数设置不合理等初级问题等，这一点看上去很简单，实际上出错的几率非常大。
针对于图像任务的标签选取不同的损失优化函数，常见针对于非连续的数据标签如分类问题，可以选取softmax cross entropy loss	的集合，亦可以针对于每个分类标签设置为多个二分类的问题，然后多个的二分类的标签联合训练使用交叉熵loss进行训练，当然这两种loss本身具有很多相似的地方，且在类别中只有两类的时候，具有相同的表达形式，但由于softmax with cross entropy loss的简洁形式，往往再多分类问题中选取这种损失函数。
我们也做了一些相关性的对比实验，发现整个模型的效果和时间都较之前有了很大的提升。
（插入图表 todo）

\section{人脸属性识别的多任务模型}
如同上文提到的，人脸属性数据库的构建慢慢从一个单属性数据库的建设变为多属性。那么模式识别的任务也从对于单个的人脸属性进行识别，变为对于人脸图片的多种属性进行预测，如果针对每一个属性都完全独立出来，设计一个模型，那么其模型复杂度过大。因此，能否设计一个模型来实现多属性的识别呢？答案是肯定的，也是可行的。近几年人脸多属性识别的任务同样具有很多的进展，使得人脸多属性识别在相关数据集和场景中有了很大的进展。下面介绍一下具体情况和我的贡献：
基于单任务的多属性学习

首先可以考虑将人脸属性多任务转化为人脸单任务的做法，可以对于多属性的人脸标签分为以下几种情况：
方法一：标签编码：
将多属性标签组合进行编码（比如，将一岁亚洲男性标记为001，将一岁非洲男性标记为002等），将多属性问题转化为分类编码问题，也就是单一属性。
局限性：
但是，对于属性数目较多的情况，这种方式会引起数据的组合爆炸。因此，该方法只适合属性数目很小的情形。

方法二：多标签回归
通过回归的方法，使预测的特征向量与Groud-truth属性向量的损失越来越小，二者趋向接近，由此得到预测的特征向量。
局限性：在提特征阶段，虽然有几十个属性，但用的都是同样的特征，未考虑不同属性的相关性和差异性。
但是无论如何设计，强行转化为单任务的算法方式，不仅非常生硬不能很好拟合属性之间和属性内部的分布关系，而且看上去也非常不优雅。

基于多任务的属性学习：
正如上文提到的，属性之间具有非常大的异构性，但是作为人脸特征，它们同时在很多表现过程之中，也有很多共同的地方，那么在设计的过程中我们更倾向于用的是单框架多任务方式。这也利用属性之间的相关性，包括正相关和负相关等来进行互相补足；同时多任务的方式设计也应对属性之间的异质性，比如年龄是可量化的，而种族是类别化的，这就需要不同的处理方式。
我们对CelebA数据集的40个属性做了成对的co-occurrence计算，它揭示了，属性的相关性是普遍存在的，且我们认为它对属性学习有所帮助。
（加入co-occurrence的图片）


不得不提的是，在完成这一任务的过程中，有两种方法对我产生了一定的影响，一个是Ziwei Liu和Ping Luo在2015年ICCV上发表的Deep Learning Face Attributes in the Wild，另一个是Hu Han在2017年同样是T-PAMI上发表的Heterogeneous Face Attribute Estimation: A Deep Multi-Task Learning Approach。这两篇论文分别代表了前CNN和后CNN时代，人脸属性多任务识别的不断演变和进展。

ZiWei Liu提出了一个新的在非限制性场景下进行属性预测的深度学习框架。通过级联两个神经网络，LNet和ANet，它们与属性标签一起进行细调，但是预训练方式不同.LNet通过大规模的一般对象类别预先训练用于人脸定位，而ANet通过大量的人脸识别进行预训练以进行属性预测。这个框架（1）它展示了人脸定位（LNet）和属性预测（ANet）的性能如何通过不同的预培训策略改善。 （2）它揭示了尽管LNet的滤波器只是使用像素级别属性标签进行finetune，但是它们在整个图像上的响应映射具有强烈的脸部位置指示。这个事实使得能够训练LNet用于仅具有图像级别注释的面部定位，但没有所有属性识别工作所需的面部边界框或地标。 （3）也证明了ANet的高级隐含神经元经过大规模人脸识别预训练后自动发现语义概念，经过与属性标记的微调后，这些概念得到了极大的丰富。每个属性都可以用这些概念的稀疏线性组合来解释。
（加入 LIU ZiWEI的 图）
Hu提出了一个深度多任务学习（DMTL）方法来联合估计来自单个人脸图像的多个异构属性。所提出的DMTL包括一个早期阶段的所有属性的共享特征学习，然后是异类属性类别的特定类别特征学习（见图2）。考虑单个卷积神经网络（CNN）中的属性相关性和属性异质性，对有序与无序性和整体与局部异质性的共同考虑导致四种类型的子网络：整体 - 名义，整体 - 顺序，局部 - 名义和局部 - 顺序。 每种类型子网的损失函数的选择仍然取决于子网是名义上的还是有序的，共享特征学习自然地利用任务之间的关系来实现强健的和有区别的特征表示。类别特定的特征学习旨在对共享特征进行精细调整，以便对每个异构属性类别进行最优估计。由于有效的共享特征学习和类别特定的特征学习，所提出的DMTL在保持低计算代价的同时，实现了有希望的属性估计精度，使其在许多人脸识别应用中具有价值。
值得一提的是，HU解决了一个我在Ziwei的工作中一直迷惑的点，那就是对于属性的学习率动态调整的问题，解决的办法也很简单，就是使用简单的两层全连接网络，对于不同性质的子网络进行单独学习，他们认为图像空间和标签空间有一个高度非线性的关系，可以表示成F，数据可以表示为D，X（图像），Y（属性）
（加入Hu 网络结构图 和高度非线性关系的图，加入celeA co-occurrence图）
Hu的工作非常全面，在所以的数据集上都进行了评测，同时也一定程度上探究了人脸属性对于不同数据集的泛化能力。
（加入HU celeA测试LFW的表格）

\section{对于不同标注数据集中人脸数据的充分利用}
上面的两个工作其实已经解决了神经网络对于人脸属性的多任务学习问题，但是他们都有一个共同的缺点那就是，对于人脸数据的利用程度还不够，例如，虽然在各个数据集上Hu都进行了一定的评测，但是很明显，不同数据集的结果互相之间具有很大的差距，使用celeA训练的数据对于lfwA的数据效果并不好，实际上加入lfwA的数据训练就可以提升相关lfwA上的准确率。但需要注意的是LFWA的数据量远小于celeA的数据量，合起来训练，两个数据库之前的差异分布其实并不能得到特别好的弥补，训练的准确率还是不能和单独使用lfwA相比。
类似的问题更严峻一点，对于年龄这一属性，不同的数据库标注是不一样的，在morph中是连续的标签，但是在adience数据集上，年龄的标注是7个单独的类别，如果强行进行label的转换就会存在很多不匹配的现象，无法对其进行测试，但根据adience重新finetune，那么就会存在类似的数据匹配和模型输出改变的问题。
为了解决这一问题，我打破思维的限制，数据集并行训练的方式来解决这一问题，对于不同的数据集来讲，预处理的方式往往类似，也就是说输入图片虽然不同，但是输入的格式是一致的（事实上即使不同也没有什么问题，关键是图片数据不同），但是因为标签不同，导致在一个网络结构中无法进行统一的训练。那么不妨就按照多个单独的网络对于图像进行训练，每个网络在特征提取阶段采用相同参数的全卷及网络结构进行特征提取，但每一层的特征图会单独进行存储，训练的时候每个数据集都按照自己的数据结构特性为了拟合loss层的设计，采用不同的子网络结构。



\section{人脸属性识别中的网络能力自评估模块的设计}
这一部分主要希望讨论个人关于关于神经网络模式识别模型的评估的一些想法，在实验室的环境下，评价一个模型的好坏，一般的方法是测试他在公开测试集上的准确率；在实际的工程开发过程之中，评价模型的方法往往是现实的视频图片中的使用效果；如果实验室评测的公开数据集能够很好的代表实际中所使用的数据，那么二者才可以具有相同的参考价值，很遗憾即使是千万级的图像数据集也不能够完全代表和预测现实场景中所会遇到的问题，同样过多的图片训练，也往往意味着需要参数更加复杂的模型进行训练，对于训练的难度和实用性都提出了新的要求。

但科学实验就是需要数值化的测试方法，并且人们相信至少我们先想办法吧准确率提高上去，这样以后面对新的困难，即使采用蚕食的方式也可以有类似的方式克服困难。这个想法激励着整个cv界的科研人员，也造成了CV界看上去是一个靠数据集吃饭的状态。学术界针对于数据集进行准确率的提升和算法的改进和思考，工业界将相关的算法应用到实际的场景之中，进行不断优化以及寻找使用场景创造社会价值这就是整个计算机人工智能行业良好发展的一个重要原因。

但是准确率不不应该是唯一的评价标准，如【fake image】里面提到的一样，模型的稳定性同样是一个很重要的评价标准，

加入背景类/模型自信度类别

改进softmax



在训练和测试数据都和
顾名思义，是为了在实际的使用过程中，
这一部分的设计首先来讲一下实现，
在评估网络的
这一部分主要是针对于网络在实际使用中出现的不稳定性问题进行设计的，无论多么准确的模型，准确率都不能达到100\%，也就是说会出现一定程度上的判断错误。


我们在训练和测试
的过程中大多数的精力也集中在错误的样本上。这样的做法其实和真实的人类思考模式有所偏差。如果我们把网络比喻成人类一样，具有一定的思考能力，也就是说输入的图片其实是
经过一定的思考而产生，思考的过程可以从表面上对应着各种特征层面的计算，不同的是网络输出
